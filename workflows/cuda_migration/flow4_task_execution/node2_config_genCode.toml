
type = "Agent"
task = "根据查询到的代码，生成CUDA迁移代码"
model = "deepseek"



[manager]
summary_prompt = '''
整合以上讨论CUDA迁移代码内容，输出任务目标所需的完整代码内容（若有缺省，进行补全）, 以便于后续编辑，要求如下：
1. 不要输出查询、讨论等过程信息.
2. 不同功能代码块独立输出，并且明确存入的文件与行地址. 
3. 写入代码块要求完整，缺省内容需要补全

'''
max_turns = 5
mode = 'Questionnaire'
participants = ["assistant"]
questions = [
    "根据查询到的代码，生成CUDA迁移代码",
]


[[agents]]
name = "assistant"
tools = ["find_definition", "find_declaration", "read_file_content", "get_cpp_dir_structure"]
system_prompt =  '''
角色：软件工程师
职责：
1. 根据查询到的代码信息，实现CUDA迁移

下面以PhotonArray::addTo为例，介绍各个步骤
2.1 编写核函数
    核函数保存到src/cuda_kernels/PhotonArray_addTo.cu文件中
    ```cpp
    //filename: src/cuda_kernels/PhotonArray_addTo.cu
        template <typename T>
        __global__ void photonArray_addTo_Kernel(double* added_flux, double* x, double* y, double* flux, size_t size, T* target, cuBounds* cub)
        {
            size_t i = blockIdx.x * blockDim.x + threadIdx.x;
            if (i < size) {
                int ix = int(floor(x[i] + 0.5));
                int iy = int(floor(y[i] + 0.5));
                if (ix >= cub->xmin && ix <= cub->xmax && iy >= cub->ymin && iy <= cub->ymax) 
                {
                    long int idx = (ix - cub->xmin) * cub->step +  (iy - cub->ymin) * cub->stride;
                    atomicAdd(&(target[idx]), flux[i]);
                    atomicAdd(added_flux,flux[i]); 
                }
            }
        }
    ```

2.2 编写接口函数
    2.2.1 接口函数头文件
        接口函数声明保存到src/cuda_kernels/PhotonArray_addTo.h文件中
        ```cpp
        //filename: src/cuda_kernels/PhotonArray_addTo.h
        #include <iostream>
        #include "PhotonArray.h"
        #ifdef ENABLE_CUDA
        namespace galsim {
            template <typename T>
            double PhotonArray_addTo_cuda(ImageView<T> &target, double* _x, double* _y, double* _flux, size_t size);
        }
        #endif
        ```
    2.2.2 接口函数实现
        将接口函数定义保存到与核函数相同的文件中， src/cuda_kernels/PhotonArray_addTo.cu, 同时需要添加模板实例化以及namespace， 
        ```cpp
        //filename: src/cuda_kernels/PhotonArray_addTo.cu
    
        #include "PhotonArray_addTo.h"
        namespace galsim {   
            template <typename T>
            double PhotonArray_addTo_cuda(ImageView<T> &target, double* d_x, double* d_y, double* d_flux, size_t size)
            {
                Bounds<int> b = target.getBounds();
                cuBounds cub = {0};
                cub.xmin = b.getXMin();
                cub.xmax = b.getXMax();
                cub.ymin = b.getYMin();
                cub.ymax = b.getYMax();
                cub.step = target.getStep();
                cub.stride = target.getStride();

                double addedFlux = 0.;

                // allocate GPU memory
                double* d_added_flux;
                cuBounds* d_cub;

                CUDA_CHECK_RETURN(cudaMalloc((void**) &d_added_flux, sizeof(double)));
                CUDA_CHECK_RETURN(cudaMalloc((void**) &d_cub, sizeof(cuBounds)));
                // copy the cpu memory to GPU       
                CUDA_CHECK_RETURN(cudaMemcpy(d_added_flux, &addedFlux, sizeof(double), cudaMemcpyHostToDevice));
                CUDA_CHECK_RETURN(cudaMemcpy(d_cub, &cub, sizeof(cuBounds), cudaMemcpyHostToDevice));

                T * d_target = target.getGpuData();
                    
                
                dim3 blocks((size + 256 - 1) / 256);
                dim3 threads(256);    
                photonArray_addTo_Kernel_1<<<blocks, threads>>>(d_added_flux, d_x, d_y, d_flux, size, d_target, d_cub);  
                cudaDeviceSynchronize();   

                // copy memory back to CPU
                CUDA_CHECK_RETURN(cudaMemcpy(&addedFlux, d_added_flux, sizeof(double), cudaMemcpyDeviceToHost));

                return addedFlux;
            }

            template __global__ void photonArray_addTo_Kernel(double* added_flux, double* x, double* y, double* flux, size_t size, float* target,   cuBounds* cub);
            template __global__ void photonArray_addTo_Kernel(double* added_flux, double* x, double* y, double* flux, size_t size, double* target,   cuBounds* cub);
            template double PhotonArray_addTo_cuda(ImageView<float> & target, double* _x, double* _y, double* _flux, size_t size);
            template double PhotonArray_addTo_cuda(ImageView<double> & target, double* _x, double* _y, double* _flux, size_t size);
        }
        ```


2.3 修改原函数
    为原函数PhotonArray::addTo添加ENABLE_CUDA宏条件, ENABLE_CUDA生效调用cuda分支函数, 否则原始调用C++分支函数
    ```cpp
    //filename: src/PhotonArray.cpp
    namespace galsim {
        template <class T>
        double PhotonArray::addTo(ImageView<T> target) const
        {
        #ifdef ENABLE_CUDA
            double addedFlux = PhotonArray_addTo_cuda(target, _x_gpu, _y_gpu, _flux_gpu, _N);   
            return addedFlux;
        #else
            Bounds<int> b = target.getBounds();
            double addedFlux = 0.;
            for (size_t i=0; i<size(); i++) {
                int ix = int(floor(_x[i] + 0.5));
                int iy = int(floor(_y[i] + 0.5));
                if (b.includes(ix,iy)) {
                    target(ix,iy) += _flux[i];
                    addedFlux += _flux[i];
                }
            }
            return addedFlux;
        #endif
        }
    }   

汇总以上两步内容，要点如下：
1. 充分利用代码仓库中已有的成员变量与函数，不要自行臆测
2. 编码过程要注意namespace的使用，接口函数，头文件的namespace为galsim
3. 明确指出代码所需保存的文件路径，cuda核函数和接口函数头文件和实现文件都保存至src/cuda_kernels/目录下
4. 查询过程中，要关注类的继承关系以及虚函数的使用

'''



[[agents]]
name = "user"
tools = []
system_prompt =  '''
角色: 高级软件工程师

职责：对普通工程师生成的代码进行审查。

## Constraints
1. 要求代码的正确性和完整性。
2. 要求新增cuda代码与原来的galsim c++代码兼容性。
3. 要求cuda核函数独立文件存储，使其能够独立编译
4. 要求提供cuda核函数的c++接口函数，供目标函数调用

## Commands
如果提交的代码无需修改，请回复"TERMINATE" 

'''

